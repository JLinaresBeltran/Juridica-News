# Sistema de Web Scraping Jur√≠dico

## üéØ Visi√≥n General

El Sistema de Web Scraping Jur√≠dico es un componente especializado del **Sistema Editorial Jur√≠dico Supervisado** dise√±ado para la extracci√≥n automatizada de documentos jur√≠dicos de fuentes oficiales, espec√≠ficamente enfocado en la **Corte Constitucional de Colombia**.

### Caracter√≠sticas Principales

- üîç **Extracci√≥n Inteligente**: B√∫squeda autom√°tica en d√≠as h√°biles anteriores cuando no hay documentos recientes
- üöó **Web Scraping Robusto**: Implementado con Selenium para manejar sitios web din√°micos
- üìä **Integraci√≥n Completa**: Comunicaci√≥n directa con la API del sistema editorial
- ‚ö° **Optimizaci√≥n de Rendimiento**: Cache de URLs y verificaci√≥n inteligente de documentos
- üõ°Ô∏è **Manejo de Errores**: Sistema resiliente con m√∫ltiples estrategias de recuperaci√≥n

## üèóÔ∏è Arquitectura del Sistema

### Estructura de Directorios

```
backend/services/scraping/
‚îú‚îÄ‚îÄ base.py                        # Clase base abstracta para extractores
‚îú‚îÄ‚îÄ corte_constitucional_extractor.py  # Extractor especializado CC
‚îú‚îÄ‚îÄ run_extractor.py              # Script de ejecuci√≥n principal  
‚îú‚îÄ‚îÄ download_single.py            # Descarga de documentos individuales
‚îú‚îÄ‚îÄ venv/                        # Entorno virtual Python
‚îî‚îÄ‚îÄ documents/                   # Directorio de almacenamiento local
    ‚îú‚îÄ‚îÄ rtf/                    # Documentos RTF
    ‚îî‚îÄ‚îÄ docx/                   # Documentos DOCX
```

### Componentes Principales

#### 1. **BaseExtractor** (`base.py`)

Clase abstracta que define la interfaz com√∫n para todos los extractores jur√≠dicos.

```python
@dataclass
class DocumentMetadata:
    source: str                  # Fuente del documento (ej: "corte_constitucional")
    document_id: str            # ID √∫nico del documento (ej: "T-343/25")
    title: str                  # T√≠tulo completo de la sentencia
    date: datetime              # Fecha de la sentencia
    court: str                  # Tribunal emisor
    document_type: str          # Tipo de sentencia (T, C, SU, A)
    pdf_url: str               # URL del documento RTF/DOCX
    html_url: str              # URL de la versi√≥n HTML
    extraction_date: datetime   # Fecha de extracci√≥n
    magistrate: str            # Magistrado ponente
```

#### 2. **CorteConstitucionalExtractor** (`corte_constitucional_extractor.py`)

Extractor especializado que implementa la l√≥gica espec√≠fica para la Corte Constitucional.

**Caracter√≠sticas t√©cnicas:**
- **Driver**: Selenium WebDriver con Chrome headless
- **Estrategia de b√∫squeda**: D√≠as h√°biles retrospectivos (7 d√≠as normal, 15 extendido)
- **Patrones de reconocimiento**: Regex avanzado para identificar sentencias
- **Verificaci√≥n de URLs**: Sistema de cache con TTL de 1 hora
- **Formatos soportados**: RTF, DOCX

#### 3. **Script de Ejecuci√≥n** (`run_extractor.py`)

Interfaz de l√≠nea de comandos para ejecutar el extractor desde Node.js.

**Par√°metros:**
```bash
--source corte_constitucional  # Fuente a extraer
--limit 10                    # N√∫mero m√°ximo de documentos
--download                    # Flag para descarga local opcional
```

#### 4. **Descarga Individual** (`download_single.py`)

Utilidad para descargar documentos espec√≠ficos por URL e ID.

## üîß Configuraci√≥n y Instalaci√≥n

### Prerrequisitos

```bash
# Python 3.9+
python3 --version

# Google Chrome (para Selenium)
google-chrome --version
```

### Instalaci√≥n del Entorno Virtual

```bash
cd backend/services/scraping/
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Dependencias Principales

```python
# Web Scraping
selenium==4.15.2
webdriver-manager==4.0.1

# HTTP Requests  
requests==2.31.0

# Procesamiento de datos
python-dateutil==2.8.2
```

## üöÄ Uso del Sistema

### 1. Extracci√≥n B√°sica

```bash
# Extraer 5 documentos sin descargar
python run_extractor.py --source corte_constitucional --limit 5

# Extraer y descargar documentos
python run_extractor.py --source corte_constitucional --limit 10 --download
```

### 2. Desde Node.js (Integraci√≥n Completa)

```javascript
// backend/src/services/ScrapingService.ts
const result = await execAsync(`
    ${pythonPath} ./backend/services/scraping/run_extractor.py 
    --source corte_constitucional 
    --limit ${limit}
`);
```

### 3. Descarga Individual

```bash
python download_single.py \
    --url "https://www.corteconstitucional.gov.co/sentencias/2025/t-343-25.rtf" \
    --id "T-343/25"
```

## ‚öôÔ∏è Funcionamiento Interno

### Algoritmo de B√∫squeda de D√≠as H√°biles

```python
def _get_extraction_dates(self, extended_search: bool = False):
    # Configuraci√≥n de b√∫squeda
    days_to_search = 15 if extended_search else 7
    
    # B√∫squeda solo en d√≠as h√°biles (lunes-viernes)
    current_date = datetime.now()
    while days_added < days_to_search:
        if current_date.weekday() < 5:  # 0=lunes, 4=viernes
            dates_to_extract.append(current_date)
            days_added += 1
        current_date -= timedelta(days=1)
```

### Patrones de Reconocimiento de Sentencias

```python
sentence_patterns = [
    r'([TCG]-\d{1,4}[/-]\d{2,4})',    # T-343/25, C-123/25
    r'(SU\.\d{1,4}[/-]\d{2,4})',     # SU.123/25
    r'(SU-\d{1,4}[/-]\d{2,4})',      # SU-123/25  
    r'([A]-\d{1,4}[/-]\d{2,4})',     # A-123/25
    r'([TCG]\d{1,4}[/-]\d{2,4})',    # Sin gui√≥n
    r'(SU\d{1,4}[/-]\d{2,4})'        # SU sin punto
]
```

### Generaci√≥n de URLs

```python
def _generate_document_url(self, sentence_number: str) -> str:
    """
    Transforma: T-343/25 ‚Üí t-343-25.rtf
    URL final: https://www.corteconstitucional.gov.co/sentencias/2025/t-343-25.rtf
    """
    clean_number = sentence_number.strip().upper()
    normalized_id = clean_number.lower().replace('/', '-')
    return f"{base_url}/sentencias/{year}/{normalized_id}.rtf"
```

## üìä Flujo de Datos

```mermaid
graph TD
    A[Node.js API] --> B[run_extractor.py]
    B --> C[CorteConstitucionalExtractor]
    C --> D[Selenium WebDriver]
    D --> E[Sitio Web CC]
    E --> F[An√°lisis HTML]
    F --> G[Extracci√≥n de Metadatos]
    G --> H[Verificaci√≥n URLs]
    H --> I[Descarga Opcional]
    I --> J[JSON Response]
    J --> K[Base de Datos]
```

## üîç Tipos de Documentos Extra√≠dos

### Sentencias de Tutela (T)
- **Formato**: T-XXX/YY (ej: T-343/25)
- **Descripci√≥n**: Protecci√≥n de derechos fundamentales
- **Frecuencia**: M√∫ltiples diarias

### Sentencias de Constitucionalidad (C)  
- **Formato**: C-XXX/YY (ej: C-223/25)
- **Descripci√≥n**: Control constitucional de normas
- **Frecuencia**: Semanal aproximadamente

### Sentencias de Unificaci√≥n (SU)
- **Formato**: SU-XXX/YY o SU.XXX/YY
- **Descripci√≥n**: Unificaci√≥n de jurisprudencia
- **Frecuencia**: Ocasional

### Autos (A)
- **Formato**: A-XXX/YY
- **Descripci√≥n**: Decisiones procesales
- **Frecuencia**: Variable

## üìà M√©tricas y Monitoreo

### Logging Estructurado

```python
# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s'
)

# Ejemplos de logs
logger.info("üöÄ Iniciando extracci√≥n - Fuente: corte_constitucional, L√≠mite: 10")
logger.info("üîç Buscando en 7 fechas h√°biles") 
logger.info("‚úÖ 4 sentencias encontradas para 3 de septiembre de 2025")
logger.warning("‚ùå URL inv√°lida: T-343/25")
```

### M√©tricas de Rendimiento

- **Tiempo de extracci√≥n**: ~30-45 segundos por ejecuci√≥n
- **Documentos por ejecuci√≥n**: 0-10 documentos t√≠picamente
- **Tasa de √©xito URLs**: >80% de URLs v√°lidas
- **Cache hit ratio**: >60% en URLs verificadas

## üõ†Ô∏è Configuraci√≥n Avanzada

### Optimizaci√≥n de Chrome WebDriver

```python
chrome_options = Options()
chrome_options.add_argument("--headless=new")      # Sin interfaz gr√°fica
chrome_options.add_argument("--no-sandbox")        # Seguridad containers
chrome_options.add_argument("--disable-gpu")       # Sin aceleraci√≥n GPU
chrome_options.add_argument("--disable-images")    # Sin carga de im√°genes
chrome_options.add_argument("--window-size=1920,1080")  # Resoluci√≥n fija
```

### Manejo de Errores

```python
try:
    documents = extractor.extract_latest_sentences(limit)
except TimeoutException:
    logger.warning("‚ö†Ô∏è Timeout esperando carga de Angular")
except NoSuchElementException:
    logger.error("‚ùå Elemento no encontrado en DOM")
except Exception as e:
    logger.error(f"‚ùå Error inesperado: {e}")
```

## üîí Seguridad y Buenas Pr√°cticas

### Headers de Solicitud

```python
headers = {
    'User-Agent': 'SistemaEditorialJuridico/1.0',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'es-CO,es;q=0.8,en;q=0.6',
    'Accept-Encoding': 'gzip, deflate',
    'Connection': 'keep-alive',
}
```

### L√≠mites de Rate

- **Delay entre p√°ginas**: 1-3 segundos
- **Timeout de p√°gina**: 30 segundos m√°ximo
- **Reintentos**: Hasta 3 intentos por documento
- **Cache TTL**: 1 hora para verificaci√≥n de URLs

### Validaci√≥n de Contenido

```python
def _verify_document_url(self, url: str) -> bool:
    """Verifica que la URL contenga documento real, no HTML de error"""
    content_type = response.headers.get('content-type', '').lower()
    return 'text/html' not in content_type
```

## üö® Soluci√≥n de Problemas Comunes

### Error: "URL inv√°lida"
**Causa**: URL no accesible o retorna HTML en lugar de documento
**Soluci√≥n**: Verificar patrones regex y generaci√≥n de URLs

### Error: "ChromeDriver format error"
**Causa**: Driver incompatible con arquitectura del sistema
**Soluci√≥n**: Configuraci√≥n alternativa se aplica autom√°ticamente

### Error: "Connection refused API"
**Causa**: API local no disponible para verificar BD vac√≠a
**Soluci√≥n**: Contin√∫a con b√∫squeda normal autom√°ticamente

### Sin documentos extra√≠dos
**Causa**: Fechas sin sentencias publicadas
**Soluci√≥n**: Aumentar n√∫mero de d√≠as de b√∫squeda o usar modo extendido

## üîÑ Integraci√≥n con el Sistema Principal

### API Endpoints Relacionados

```typescript
// Trigger de extracci√≥n
POST /api/scraping/extract
{
  "source": "corte_constitucional",
  "limit": 10,
  "download": false
}

// Estado de extracci√≥n  
GET /api/scraping/status/:jobId

// Documentos extra√≠dos
GET /api/documents?source=corte_constitucional&recent=true
```

### Base de Datos

Los documentos extra√≠dos se almacenan en la tabla `documents` con:

```sql
-- Campos espec√≠ficos de scraping
source: 'corte_constitucional'
document_id: 'T-343/25' 
pdf_url: 'https://www.corteconstitucional.gov.co/sentencias/2025/t-343-25.rtf'
extraction_date: TIMESTAMP
status: 'scraped' | 'downloaded' | 'processed'
```

## üìÖ Mantenimiento y Actualizaciones

### Tareas Peri√≥dicas

- **Diario**: Verificaci√≥n autom√°tica de nuevos documentos
- **Semanal**: Limpieza de cache y archivos temporales  
- **Mensual**: Actualizaci√≥n de dependencias Python
- **Trimestral**: Revisi√≥n de patrones de extracci√≥n

### Logs de Auditoria

Todos los procesos de scraping se registran en:
- **Sistema de logs**: Winston (Node.js) + Python logging
- **Base de datos**: Tabla `audit_logs` con detalles de extracci√≥n
- **M√©tricas**: Tiempo de respuesta, √©xito/fallo, documentos encontrados

## üîÆ Planes Futuros

### Pr√≥ximas Fuentes
- **Consejo de Estado**: Sentencias de lo contencioso administrativo
- **Corte Suprema de Justicia**: Casaci√≥n civil y penal  
- **Tribunales Superiores**: Decisiones de segunda instancia

### Mejoras T√©cnicas
- **Paralelizaci√≥n**: Extracci√≥n simult√°nea de m√∫ltiples fuentes
- **Machine Learning**: Clasificaci√≥n autom√°tica por temas jur√≠dicos
- **OCR Integration**: Procesamiento de documentos escaneados
- **Real-time**: Notificaciones push de nuevos documentos

---

**Versi√≥n del Documento**: 1.0  
**√öltima Actualizaci√≥n**: Septiembre 2025  
**Mantenido por**: Sistema Editorial Jur√≠dico Supervisado